{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook is for the Datathon I participated in 04/05/2020.\n",
    "#The original dataset is about the consumer complaints about Financial companies, provided by CFPB, Consumer Financial Protection Bureau.\n",
    "#Source: https://catalog.data.gov/dataset/consumer-complaint-database#topic=consumer_navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "df = pd.read_csv('./complaints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "print(df['Product'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#product and subproduct variable issue\n",
    "#There are 10 types of official products. However, in the df dataset, there are 18 types of products. But this problem doesn't exist in the dataset starting from 01/05/2017. \n",
    "#Therefore, we don't have to run this cell if we run the datatime cell first.\n",
    "\n",
    "df.loc[df['Product']=='Credit reporting','Product'] = 'Credit reporting, credit repair services, or other personal consumer reports'\n",
    "df.loc[df['Product']=='Credit card','Product'] = 'Credit card or prepaid card'\n",
    "df.loc[df['Product']=='Bank account or service','Product'] = 'Checking or savings account'\n",
    "df.loc[df['Product']=='Consumer Loan','Product'] = 'Payday loan, title loan, or personal loan'\n",
    "df.loc[df['Product']=='Payday loan','Product'] = 'Payday loan, title loan, or personal loan'\n",
    "df.loc[df['Product']=='Money transfers','Product'] = 'Money transfer, virtual currency, or money service'\n",
    "df.loc[df['Product']=='Prepaid card','Product'] = 'Credit card or prepaid card'\n",
    "df.loc[df['Product']=='Virtual currency','Product'] = 'Money transfer, virtual currency, or money service'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need data start from 05/2017 to 03/2020, because the old data do not provide much useful information.\n",
    "import time\n",
    "from datetime import datetime\n",
    "df['Date received'] = pd.to_datetime(df['Date received'], format = '%Y-%m-%d')\n",
    "df['Date sent to company'] = pd.to_datetime(df['Date sent to company'], format = '%Y-%m-%d')\n",
    "\n",
    "#only use data after 20170501\n",
    "b = df.loc[df['Date received'] >='2017-05-01',:]\n",
    "#print(b.info())\n",
    "print(b['Product'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we take a look at the pie chart of the products, we can see that the credit reporting variable occupies almost half of the products, which means almost 50% of the compliants were about the credit reporting issues.\n",
    "#Therefore, we will dive into this product and find out what happened with the credit reporting.\n",
    "#show the pie chart of products.\n",
    "product = b['Product'].value_counts()\n",
    "dfproduct = pd.DataFrame({'product_type':product.index[0:], 'counts': product.values[0:]})\n",
    "#dfproduct\n",
    "fig = plt.figure(figsize =[13, 5])\n",
    "plt.pie(dfproduct.counts, labels = dfproduct.product_type, autopct = '%1.2f%%' )\n",
    "plt.title('product pie chart')\n",
    "plt.savefig('productc.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data of credit reporting issues only.\n",
    "c = b.loc[b['Product']=='Credit reporting, credit repair services, or other personal consumer reports',:]\n",
    "c.info()\n",
    "#rename the product\n",
    "c.loc[c['Product'] == 'Credit reporting, credit repair services, or other personal consumer reports','Product'] = 'CreditRpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the missing values\n",
    "missing = c.isna().sum()\n",
    "print(missing)\n",
    "#drop the variables with much missing values\n",
    "c = c.drop(columns = ['Tags','Consumer disputed?'])\n",
    "print(c.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nlp data and features with much null values for Tableau\n",
    "d = c.drop(columns = ['Consumer complaint narrative'])\n",
    "d.to_csv('./creditrpt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following EDA is by Tableau.\n",
    "#Python is used for generating a wordcloud picture.\n",
    "#The wordcloud part uses the consumer complaint narratives only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#about nlp data- c\n",
    "c = c['Consumer complaint narrative']\n",
    "c.dropna(inplace = True)\n",
    "\n",
    "c.to_csv('./narrative.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate word cloud.\n",
    "#nlp2\n",
    "# 词云展示\n",
    "!pip install nltk\n",
    "!pip install pillow\n",
    "!pip install lxml\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from lxml import etree\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "# 去掉停用词\n",
    "def remove_stop_words(f):\n",
    "\n",
    "    f_stop = open('./stopword111.txt', encoding='utf-8')\n",
    "    try:\n",
    "        f_stop_text = f_stop.read( )                      #获取停用词词表中的内容\n",
    "    finally:\n",
    "        f_stop.close( )\n",
    "    stop_words = f_stop_text.split('\\n')\n",
    "     \n",
    "    for stop_word in stop_words:\n",
    "        f = f.replace(stop_word, '')\n",
    "    return f\n",
    "\n",
    "# 生成词云\n",
    "def create_word_cloud(f):\n",
    "    print('根据词频，开始生成词云!')\n",
    "    f = remove_stop_words(f)\n",
    "    cut_text = word_tokenize(f)\n",
    "    #print(cut_text)\n",
    "    cut_text = \" \".join(cut_text)\n",
    "    wc = WordCloud(\n",
    "        max_words=100,\n",
    "        width=2000,\n",
    "        height=1200,\n",
    "    )\n",
    "    wordcloud = wc.generate(cut_text)\n",
    "\t# 写词云图片\n",
    "    wordcloud.to_file(\"wordcloud.jpg\")\n",
    "    # 显示词云文件\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# 数据加载\n",
    "\n",
    "def getText():\n",
    "    txt=open(\"./narrative.txt\",\"r\",encoding='utf-8').read() #打开文件\n",
    "    txt=txt.lower()                  #将所有单词转换为小写去掉大小写的干扰\n",
    "    for ch in '`!@#~$%^&*()_+-=*/{}[];,./?<>': #去掉所有的特殊符号\n",
    "        txt=txt.replace(ch,\" \")   #将特殊符号替换成空格 即去掉\n",
    "    return txt\n",
    "hmltTxt=getText()    #对文件进行读取\n",
    "all_word=hmltTxt.split()\n",
    "\n",
    "# 生成词云\n",
    "create_word_cloud(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT RUN THIS CELL!!!\n",
    "\n",
    "#nlp1\n",
    "#https://blog.csdn.net/HuangZhang_123/article/details/80277793\n",
    "def getText():\n",
    "    txt=open(\"./narrative.txt\",\"r\",encoding='utf-8').read() #打开文件\n",
    "    txt=txt.lower()                  #将所有单词转换为小写去掉大小写的干扰\n",
    "    for ch in '`!@#~$%^&*()_+-=*/{}[];,./?<>': #去掉所有的特殊符号\n",
    "        txt=txt.replace(ch,\" \")   #将特殊符号替换成空格 即去掉\n",
    "    return txt\n",
    "hmltTxt=getText()    #对文件进行读取\n",
    "words=hmltTxt.split()\n",
    "#因为现在单词间均为空格分隔开来，所以用split用空格分隔他们并变成列表返回\n",
    "counts={} #建立一个字典\n",
    "for word in words:\n",
    "    counts[word]=counts.get(word,0)+1\n",
    "    #用当前的某一个单词作为键索引字典 如果在里面则返回次数再加一 若不在里面则直接加1\n",
    "items=list(counts.items())\n",
    "#用list将counts变为一个列表类型  counts.items()-->返回可遍历的（键，值）元组数组\n",
    "items.sort(key=lambda x:x[1],reverse=True)\n",
    "#使用list.sort()方法来排序，此时list本身将被修改\n",
    "for i in range(100):\n",
    "    word,count=items[i]         \n",
    "    print(\"{0:<10}{1:>5}\".format(word,count))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
